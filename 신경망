신경망(Neural Network) : 뇌구조를 모방한 계산 모형
                        
                        구성 
                        입력층 - 은닉층 - 출력층
                        가중치를 갖는 층은 입력층과 은닉층




퍼셉트론(Perceptron) : 입력은 특징 벡터 X=(x1,x2,...,wx)
                       x를 두개의 부류 w1과 w2중의 하나로 분류하는 이진 분류기
                       출력 노드는 가중치 합과 활성 함수를 계산
                       계단 함수를 활성함수로 사용
                       
                       = 인공뉴런(Artificial Neuron)
                       
                       여러개의 입력된 정보에 대해 가중치 합을 계산하여 출력정보 생성
                       활성화 함수 혹은 전달함수을 통해 전달
                       
                       
                       동작원리
                           { 0 (w1x1 + w2x2 <= 임계값) }
                       y = { 1 (w1x1 + w2x2 > 임계값) }
                       
                       가중치(w)는 전류의 저항과 비슷한 의미 (가중치가 크면 더 강한 신호를 흘려 보냄)
                       뉴런에서 보내온 신호의 총합이 임계값보다 큰 경우 1을 출력 즉 활성화
                       
                       
                       
                       
다층 퍼셉트론(MLP) : 입력층 -> 은닉층 -> 출력층
                    입력층 : 특징 벡터의 차원에 따라 d개의 노드와 여분의 바이어스 노드로 구성
                    출력층 : 부류 개수에 따라 m개의 노드로 구성
                    은닉층 : 노드 개수 p를 사용자가 설정
                    
                    
                    
                    
깊은학습(Deep Learning) : MLP의 은닉층 개수를 늘린 깊은 신경망




활성함수의 종류
1) Sigmoid function(=Logistic function) : 미분이 되지 않는 지점에서 사용하는 함수
                                          계단형식의 함수를 미분이 가능하도록 곡선화 해주는 함수
                                          1과 0 사이를 부드럽게 이어줌
                                          0-1 사이의 값을 반환
                                          연속형 데이터이기에 계단함수가 끊기지 않는 매끄러운 모양
                                          이진분류 가능
2) ReLU function : 
3) 쌍곡탄젠트 : 

